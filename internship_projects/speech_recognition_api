import argparse
import json
import logging
import os
import subprocess
import tempfile
import time
import traceback
import uuid
from collections import defaultdict

import numpy as np
import requests
import torch
import torchaudio
import torchaudio.transforms as T

from clearvoice import ClearVoice
from concurrent.futures import ThreadPoolExecutor, as_completed
from flask import Flask, request, jsonify, make_response
from pyannote.audio import Pipeline
from pymilvus import Collection, CollectionSchema, connections, DataType, FieldSchema, utility
from pymilvus.orm.schema import FieldSchema as ORM_FieldSchema, DataType as ORM_DataType
from speechbrain.pretrained import SpeakerRecognition

parser = argparse.ArgumentParser(description="PyAnnote X ECAPA")
parser.add_argument('--port', type=int, default=5000, help='Port number to run the Flask app')
parser.add_argument('--is_primary', type=lambda x: (str(x).lower() == 'true'), default=False, help='Whether this is the primary instance')
parser.add_argument('--num_instances', type=int, default=5, help='Number of secondary instances to spawn if primary')

args = parser.parse_args()
port = args.port
is_primary = args.is_primary
num_instances = args.num_instances

log_filename = f'speech_{port}.log'
logging.basicConfig(
    filename=log_filename,
    filemode='a',
    format='%(asctime)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger()

if is_primary:
    for i in range(1, num_instances + 1):
        new_port = port + i
        logger.info(f"Spawning instance on port {new_port}")
        subprocess.Popen([
            "python3", "speech_recognition.py",
            "--port", str(new_port),
            "--is_primary", "False"
        ])

app = Flask(__name__)

HUGGINGFACE_TOKEN = "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"
pyannote = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1", use_auth_token=HUGGINGFACE_TOKEN).to(torch.device("cuda"))
audio_enhancement = ClearVoice(task='speech_enhancement', model_names=['MossFormerGAN_SE_16K'])
ecapa = SpeakerRecognition.from_hparams(source="speechbrain/spkrec-ecapa-voxceleb")
connections.connect()

def init_collection(collection_name):
    if utility.has_collection(collection_name):
        return

    fields = [
        FieldSchema(name="unique_id", dtype=DataType.VARCHAR, is_primary=True, max_length=150),
        FieldSchema(name="audio_id", dtype=DataType.VARCHAR, max_length=100),
        FieldSchema(name="audio_url", dtype=DataType.VARCHAR, max_length=500),
        FieldSchema(name="segments", dtype=DataType.JSON),
        FieldSchema(name="speaker_id", dtype=DataType.VARCHAR, max_length=50),
        FieldSchema(name="pyannote_embedding", dtype=DataType.FLOAT_VECTOR, dim=256),
        FieldSchema(name="ecapa_embedding", dtype=DataType.FLOAT_VECTOR, dim=192),
        FieldSchema(name="metadata", dtype=DataType.JSON),
    ]

    schema = CollectionSchema(fields, description="Speaker-wise diarized embeddings")

    collection = Collection(name=collection_name, schema=schema)
    collection.create_index(
        field_name="pyannote_embedding",
        index_params={"index_type": "IVF_FLAT", "metric_type": "COSINE", "params": {"nlist": 128}}
    )
    collection.create_index(
        field_name="ecapa_embedding",
        index_params={"index_type": "IVF_FLAT", "metric_type": "COSINE", "params": {"nlist": 128}}
    )
    collection.load()

@app.route('/collections', methods=['GET'])
def collections():
    try:
        start_time = time.time()
        logger.info("[collections][GET] Listing all collections matching the speaker schema...")

        all_collections = utility.list_collections()
        valid_collections = []

        required_fields = {
            "unique_id": DataType.VARCHAR,
            "audio_id": DataType.VARCHAR,
            "audio_url": DataType.VARCHAR,
            "segments": DataType.JSON,
            "speaker_id": DataType.VARCHAR,
            "pyannote_embedding": DataType.FLOAT_VECTOR,
            "ecapa_embedding": DataType.FLOAT_VECTOR,
            "metadata": DataType.JSON
        }

        for name in all_collections:
            try:
                collection = Collection(name)
                field_types = {field.name: field.dtype for field in collection.schema.fields}

                if all(field in field_types and field_types[field] == dtype for field, dtype in required_fields.items()):
                    collection.load()
                    count = collection.num_entities
                    display_name = name[1:] if name.startswith("_") else name
                    valid_collections.append({
                        "name": display_name,
                        "count": count
                    })
                    logger.info(f"[collections][GET] Valid collection: {display_name}, count: {count}")
                else:
                    pass
            except Exception as e:
                logger.warning(f"[collections][GET] [Schema Check Failed] Collection {name}: {e}")
                continue

        logger.info(f"[collections][GET] Total valid collections found: {len(valid_collections)}")
        logger.info(f"[collections][GET] Completed in {time.time() - start_time:.2f}s")
        return jsonify({"collections": valid_collections}), 200

    except Exception as e:
        logger.error(f"[collections][GET] Exception occurred during processing:\n{traceback.format_exc()}")
        return jsonify({"error": "Failed to list collections"}), 500

@app.route("/deletion", methods=["POST"])
def deletion():
    payload = request.get_json()
    collection_name = payload.get("collection_name")

    if not collection_name:
        return jsonify({"success": False, "message": "'collection_name' must be provided."}), 400

    try:
        if utility.has_collection(collection_name):
            Collection(collection_name).drop()
            return jsonify({"success": True, "message": f"Collection '{collection_name}' deleted successfully."})
        else:
            return jsonify({"success": False, "message": f"Collection '{collection_name}' not found."}), 404

    except Exception as e:
        return jsonify({"success": False, "message": str(e)}), 500
    
@app.route("/diarize", methods=["POST"])
def diarize():
    try:
        start_time_total = time.time()

        payload = request.get_json()
        audio_url = payload.get("audio_url")
        min_duration = float(payload.get("min_duration", 1))
        enhance_flag = str(payload.get("enhance", "False")).lower() == "true"

        if not audio_url:
            logger.info("[diarize][ERROR] Missing 'audio_url' in request body.")
            return jsonify({"error": "Missing 'audio_url' in request body"}), 400

        download_start = time.time()
        response = requests.get(audio_url)
        if response.status_code != 200:
            logger.info(f"[diarize][ERROR] Failed to download audio: {audio_url}, status: {response.status_code}")
            return jsonify({"error": f"Failed to download audio from {audio_url}"}), 400

        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(response.content)
            tmp_path = tmp_file.name
        download_end = time.time()
        logger.info(f"[diarize] Downloaded audio in {download_end - download_start:.2f} seconds.")

        if enhance_flag:
            try:
                enhancement_start = time.time()
                input_file_name = os.path.basename(tmp_path)
                output_dir = "./enhanced/MossFormerGAN_SE_16K"
                os.makedirs(output_dir, exist_ok=True)
                enhanced_path = os.path.join(output_dir, input_file_name)
                audio_enhancement(input_path=tmp_path, online_write=True, output_path="./enhanced")
                tmp_path = enhanced_path
                enhancement_end = time.time()
                logger.info(f"[diarize] Audio enhancement completed in {enhancement_end-enhancement_start}.")
            except Exception as e:
                logger.warning(f"[diarize] Enhancement failed: {str(e)}")
                return jsonify({"error": f"Audio enhancement failed: {str(e)}"}), 500

        resample_start = time.time()
        waveform, sample_rate = torchaudio.load(tmp_path)
        if waveform.shape[0] > 1:
            waveform = waveform.mean(dim=0, keepdim=True)

        if sample_rate != 16000:
            waveform = T.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)
            torchaudio.save(tmp_path, waveform, 16000)
            logger.info("[diarize] Resampled audio to 16000Hz.")
        resample_end = time.time()
        logger.info(f"[diarize] Audio loaded and processed in {resample_end - resample_start:.2f} seconds.")

        diarize_start = time.time()
        diarization, _ = pyannote(tmp_path, return_embeddings=True)
        diarize_end = time.time()
        logger.info(f"[diarize] Diarization completed in {diarize_end - diarize_start:.2f} seconds.")

        segment_start = time.time()
        speaker_segments = defaultdict(list)
        for segment, _, speaker in diarization.itertracks(yield_label=True):
            duration = float(segment.end - segment.start)
            if duration >= min_duration:
                speaker_segments[speaker].append([float(segment.start), float(segment.end)])
        segment_end = time.time()
        logger.info(f"[diarize] Speaker segment extraction with min_duration={min_duration:.2f} "
                    f"completed in {segment_end - segment_start:.2f} seconds.")

        os.remove(tmp_path)
        logger.info(f"[diarize] Removed temp file: {tmp_path}")

        total_time = time.time() - start_time_total
        logger.info(f"[diarize] Total processing time: {total_time:.2f} seconds.")

        return jsonify({audio_url: speaker_segments}), 200

    except Exception as e:
        logger.exception(f"[diarize][EXCEPTION] {str(e)}")
        return jsonify({"error": str(e)}), 500
    
@app.route('/divide_enrollment', methods=['POST'])
def divide_enrollment():
    try:
        payload = request.get_json()
        input_data = payload.get("input", [])

        logger.info(f"[divide_enrollment] Received payload with {len(input_data)} entries.")

        if not input_data:
            logger.warning("[divide_enrollment] 'input' field is missing or empty.")
            return jsonify({"success": False, "message": "Missing 'input' field"}), 400

        secondary_ports = [port + i for i in range(1, num_instances + 1)]
        logger.info(f"[divide_enrollment] Target secondary ports: {secondary_ports}")

        chunk_size = len(input_data) // num_instances
        chunks = [input_data[i * chunk_size:(i + 1) * chunk_size] for i in range(num_instances - 1)]
        chunks.append(input_data[(num_instances - 1) * chunk_size:])  

        logger.info(f"[divide_enrollment] Data divided into {len(chunks)} chunks with sizes: {[len(c) for c in chunks]}")

        base_url = "http://localhost"

        def send_request(port, chunk):
            try:
                logger.info(f"[divide_enrollment] Sending request to {base_url}:{port}/enroll with {len(chunk)} items.")
                resp = requests.post(f"{base_url}:{port}/enroll", json={"input": chunk})
                if resp.status_code == 200:
                    data = resp.json()
                    logger.info(f"[divide_enrollment] Success response from port {port}.")
                    return {
                        "success": data.get("success", []),
                        "failed": data.get("failed", [])
                    }
                else:
                    logger.warning(f"[divide_enrollment] Error response from port {port}: {resp.status_code}")
                    return {
                        "success": [],
                        "failed": chunk,
                        "message": f"Error from port {port}: {resp.status_code}"
                    }
            except Exception as e:
                logger.error(f"[divide_enrollment] Request to port {port} failed: {e}")
                return {
                    "success": [],
                    "failed": chunk,
                    "message": f"Request failed to port {port}: {e}"
                }

        responses = []
        with ThreadPoolExecutor(max_workers=num_instances) as executor:
            futures = [executor.submit(send_request, port, chunk) for port, chunk in zip(secondary_ports, chunks)]
            for future in as_completed(futures):
                responses.append(future.result())

        all_success = []
        all_failed = []

        for res in responses:
            all_success.extend(res.get("success", []))
            all_failed.extend(res.get("failed", []))

        logger.info(f"[divide_enrollment] Final success count: {len(all_success)}")
        logger.info(f"[divide_enrollment] Final failed count: {len(all_failed)}")

        return jsonify({
            "success": True,
            "message": f"Enrollment complete across {num_instances} instances. Total successful: {len(all_success)}, Failed: {len(all_failed)}",
            "success_entries": all_success,
            "failed_entries": all_failed
        })

    except Exception as e:
        logger.error(f"[divide_enrollment][POST][Exception] {e}", exc_info=True)
        return jsonify({"success": False, "message": str(e)}), 500

@app.route("/enroll", methods=["POST"])
def enroll():
    try:
        payload = request.get_json()
        if not payload or "input" not in payload:
            logger.info("[enroll][ERROR] Missing 'input' in request body.")
            return jsonify({"error": "Missing 'input' in request body"}), 400

        total_entries = len(payload["input"])
        min_duration = float(payload.get("min_duration", 1.0))

        logger.info(f"[enroll][0/{total_entries}] Received {total_entries} entries for enrollment.")
        logger.info(f"[enroll][0/{total_entries}] Using min_duration = {min_duration:.2f} seconds")

        entries_by_collection = defaultdict(list)
        success_list = []
        failed_list = []

        for idx, entry in enumerate(payload["input"]):
            prefix = f"[enroll][{idx + 1}/{total_entries}]"
            audio_id = entry.get("audio_id")
            audio_url = entry.get("audio_url")
            collection_name = entry.get("collection_name")
            enhance_flag = str(entry.get("enhance", "False")).lower() == "true"

            metadata = {k: v for k, v in entry.items() if k not in {"audio_id", "audio_url", "collection_name", "enhance"}}

            if not all([audio_id, audio_url, collection_name]):
                msg = "Missing fields in entry"
                logger.info(f"{prefix} {msg}: {entry}")
                failed_list.append({"audio_id": audio_id, "audio_url": audio_url, "message": msg})
                continue

            try:
                init_collection(collection_name)
                response = requests.get(audio_url)
                if response.status_code != 200:
                    msg = f"Download failed (status {response.status_code})"
                    logger.info(f"{prefix} {msg} for {audio_url}")
                    failed_list.append({"audio_id": audio_id, "audio_url": audio_url, "message": msg})
                    continue

                with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                    tmp_file.write(response.content)
                    tmp_path = tmp_file.name

                enhanced_path = None
                if enhance_flag:
                    try:
                        input_file_name = os.path.basename(tmp_path)
                        output_dir = "./enhanced/MossFormerGAN_SE_16K"
                        os.makedirs(output_dir, exist_ok=True)
                        enhanced_path = os.path.join(output_dir, input_file_name)
                        audio_enhancement(input_path=tmp_path, online_write=True, output_path="./enhanced")
                        tmp_path = enhanced_path 
                    except Exception as e:
                        msg = f"Enhancement failed: {str(e)}"
                        logger.warning(f"{prefix} {msg}")
                        failed_list.append({"audio_id": audio_id, "audio_url": audio_url, "message": msg})
                        os.remove(tmp_path)
                        continue

                waveform, sample_rate = torchaudio.load(tmp_path)
                if waveform.shape[0] > 1:
                    waveform = waveform.mean(dim=0, keepdim=True)

                if sample_rate != 16000:
                    waveform = T.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)
                    torchaudio.save(tmp_path, waveform, 16000)

                diarization, pyannote_embeddings = pyannote(tmp_path, return_embeddings=True)

                speaker_segments = defaultdict(list)
                for segment, _, speaker in diarization.itertracks(yield_label=True):
                    speaker_segments[speaker].append(segment)

                ecapa_embeddings = {}
                for speaker, segments in speaker_segments.items():
                    combined_waveform = torch.cat([
                        waveform[:, int(seg.start * 16000):int(seg.end * 16000)]
                        for seg in segments if int(seg.end * 16000) > int(seg.start * 16000)
                    ], dim=1)

                    if combined_waveform.shape[1] == 0:
                        logger.info(f"{prefix} Skipping empty segment for speaker: {speaker}")
                        continue

                    with torch.no_grad():
                        emb = ecapa.encode_batch(combined_waveform).squeeze().cpu().numpy()
                        emb = emb / np.linalg.norm(emb)
                        ecapa_embeddings[speaker] = emb.tolist()

                speaker_embedding_map = {spk: emb for spk, emb in zip(sorted(speaker_segments), pyannote_embeddings)}

                records = []
                for speaker, segments in speaker_segments.items():
                    valid_segments = [
                        (round(float(seg.start), 2), round(float(seg.end), 2))
                        for seg in segments
                        if round(float(seg.end) - float(seg.start), 2) >= min_duration
                    ]
                    if not valid_segments:
                        logger.info(f"{prefix} Skipping speaker {speaker} due to no valid segments.")
                        continue

                    unique_id = f"{audio_id}_{speaker}"
                    record = {
                        "unique_id": unique_id,
                        "audio_id": audio_id,
                        "audio_url": audio_url,
                        "segments": valid_segments,
                        "speaker_id": speaker,
                        "pyannote_embedding": speaker_embedding_map[speaker][:256],
                        "ecapa_embedding": ecapa_embeddings.get(speaker, [0.0] * 192),
                        "metadata": metadata
                    }
                    records.append(record)
                    logger.info(f"{prefix} Created speaker record: {unique_id} with {len(valid_segments)} segments.")

                if os.path.exists(tmp_path):
                    os.remove(tmp_path)
                if enhance_flag and enhanced_path and os.path.exists(enhanced_path):
                    os.remove(enhanced_path)

                if not records:
                    msg = "No valid speaker segments extracted"
                    failed_list.append({"audio_id": audio_id, "audio_url": audio_url, "message": msg})
                else:
                    entries_by_collection[collection_name].extend(records)
                    success_list.append({
                        "audio_id": audio_id,
                        "audio_url": audio_url,
                        "collection_name": collection_name,
                        "message": "Embedding extracted and queued"
                    })

            except Exception as e:
                logger.exception(f"{prefix} Exception during enrollment: {str(e)}")
                failed_list.append({
                    "audio_id": audio_id,
                    "audio_url": audio_url,
                    "message": str(e)
                })

        for collection_name, records in entries_by_collection.items():
            if not records:
                logger.info(f"[enroll][FINAL] No records to insert for collection: {collection_name}")
                continue

            logger.info(f"[enroll][FINAL] Inserting {len(records)} speakers into Milvus collection: {collection_name}")
            collection = Collection(collection_name)

            fields = [
                "unique_id", "audio_id", "audio_url", "segments", "speaker_id",
                "pyannote_embedding", "ecapa_embedding", "metadata"
            ]
            insert_data = {f: [r[f] for r in records] for f in fields}
            collection.insert([insert_data[f] for f in fields])
            logger.info(f"[enroll][FINAL] Insert successful: {len(records)} records inserted into {collection_name}")

        logger.info(f"[enroll][FINAL] Completed enrollment. Success: {len(success_list)}, Failed: {len(failed_list)}")
        return jsonify({
            "success": success_list,
            "failed": failed_list
        })

    except Exception as e:
        logger.exception(f"[enroll][EXCEPTION] {str(e)}")
        return jsonify({"error": str(e)}), 500

@app.route("/list_speakers", methods=["POST"])
def list_speakers():
    try:
        data = request.get_json()
        collection_name = data.get("collection_name")
        audio_id_filter = data.get("audio_id")  

        logger.info(f"[list_speakers] Received request with collection_name: '{collection_name}' and audio_id: '{audio_id_filter}'")

        if not collection_name:
            logger.warning("[list_speakers] 'collection_name' is required.")
            return jsonify({"error": "'collection_name' is required."}), 400

        if not utility.has_collection(collection_name):
            logger.error(f"[list_speakers] Collection '{collection_name}' does not exist.")
            return jsonify({"error": f"Collection '{collection_name}' does not exist."}), 404

        collection = Collection(name=collection_name)
        collection.load()
        logger.info(f"[list_speakers] Loaded collection '{collection_name}' successfully.")

        output_fields = ["audio_id", "speaker_id", "segments"]

        expr = f'audio_id == "{audio_id_filter}"' if audio_id_filter else ""

        results = collection.query(
            expr=expr,
            output_fields=output_fields,
            limit=10000
        )

        logger.info(f"[list_speakers] Retrieved {len(results)} entries from Milvus.")

        audio_speaker_segments = {}
        for item in results:
            audio_id = item["audio_id"]
            speaker_id = item["speaker_id"]
            segments = item["segments"]  

            if audio_id not in audio_speaker_segments:
                audio_speaker_segments[audio_id] = {}

            if speaker_id not in audio_speaker_segments[audio_id]:
                audio_speaker_segments[audio_id][speaker_id] = []

            for seg in segments:
                start_time = float(seg[0])
                end_time = float(seg[1])
                audio_speaker_segments[audio_id][speaker_id].append((start_time, end_time))

        logger.info(f"[list_speakers] Compiled speaker segments for {len(audio_speaker_segments)} audio_id(s).")
        return jsonify(audio_speaker_segments), 200

    except Exception as e:
        logger.exception("[list_speakers] Exception occurred during processing:")
        return jsonify({"error": str(e)}), 500
    
@app.route("/search", methods=["POST"])
def search():
    try:
        total_start_time = time.time()
        logger.info("[search] Endpoint called")

        data = request.get_json()
        collection_name = data.get("collection_name")
        audio_url = data.get("audio_url")
        speaker_id = data.get("speaker_id")
        model_type = data.get("model", "ecapa").lower()

        if not all([collection_name, audio_url, speaker_id]):
            logger.error("[search] Missing required fields: 'collection_name', 'audio_url', or 'speaker_id'")
            return jsonify({"error": "Missing one or more required fields."}), 400

        logger.info(f"[search] Input Audio URL: {audio_url}")
        if not utility.has_collection(collection_name):
            logger.error(f"[search] Collection '{collection_name}' does not exist.")
            return jsonify({"error": f"Collection '{collection_name}' does not exist."}), 404

        download_start = time.time()
        response = requests.get(audio_url)
        if response.status_code != 200:
            logger.error(f"[search] Failed to download audio from {audio_url}")
            return jsonify({"error": f"Failed to download audio from {audio_url}"}), 400
        download_time = time.time() - download_start
        logger.info(f"[search] Audio downloaded in {download_time:.2f} seconds")

        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            tmp_file.write(response.content)
            tmp_path = tmp_file.name

        waveform, sample_rate = torchaudio.load(tmp_path)
        if waveform.shape[0] > 1:
            waveform = waveform.mean(dim=0, keepdim=True)
        if sample_rate != 16000:
            waveform = T.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)
            torchaudio.save(tmp_path, waveform, 16000)

        diarize_start = time.time()
        diarization, pyannote_embeddings = pyannote(tmp_path, return_embeddings=True)
        diarize_time = time.time() - diarize_start
        logger.info(f"[search] Diarization completed in {diarize_time:.2f} seconds")

        speaker_segments = defaultdict(list)
        for segment, _, speaker in diarization.itertracks(yield_label=True):
            speaker_segments[speaker].append(segment)

        num_speakers = len(speaker_segments)
        logger.info(f"[search] Number of speakers found: {num_speakers}")

        if speaker_id not in speaker_segments:
            logger.warning(f"[search] Speaker '{speaker_id}' not found in diarization.")
            return jsonify({"error": f"Speaker '{speaker_id}' not found"}), 404

        embedding_start = time.time()
        if model_type == "ecapa":
            combined_waveform = torch.cat([
                waveform[:, int(seg.start * 16000):int(seg.end * 16000)]
                for seg in speaker_segments[speaker_id]
                if int(seg.end * 16000) > int(seg.start * 16000)
            ], dim=1)

            if combined_waveform.shape[1] == 0:
                logger.error("[search] Empty waveform for speaker after segment merge.")
                return jsonify({"error": "Empty waveform for speaker"}), 400

            with torch.no_grad():
                emb = ecapa.encode_batch(combined_waveform).squeeze().cpu().numpy()
                emb = emb / np.linalg.norm(emb)

        elif model_type == "pyannote":
            speaker_index = sorted(speaker_segments).index(speaker_id)
            emb = pyannote_embeddings[speaker_index][:256]

        else:
            logger.error(f"[search] Invalid model type '{model_type}'. Must be 'ecapa' or 'pyannote'")
            return jsonify({"error": "Invalid model, use 'ecapa' or 'pyannote'"}), 400

        embedding_time = time.time() - embedding_start
        logger.info(f"[search] Embedding extracted using '{model_type}' in {embedding_time:.2f} seconds")

        search_start = time.time()
        field_name = f"{model_type}_embedding"
        collection = Collection(name=collection_name)
        results = collection.search(
            data=[emb],
            anns_field=field_name,
            param={"metric_type": "COSINE", "params": {"nprobe": 10}},
            limit=5,
            output_fields=["unique_id", "audio_id", "audio_url", "segments"]
        )
        search_time = time.time() - search_start
        logger.info(f"[search] Search completed in {search_time:.2f} seconds")

        if not results or not results[0]:
            logger.warning("[search] No matches found")
            return jsonify({"error": "No matches found"}), 404

        matches = []
        for match in results[0]:
            matches.append({
                "audio_id": match.entity.get("audio_id"),
                "unique_id": match.entity.get("unique_id"),
                "audio_url": match.entity.get("audio_url"),
                "segments": match.entity.get("segments"),
                "similarity_score": match.distance * 100
            })

        os.remove(tmp_path)
        total_time = time.time() - total_start_time
        logger.info(f"[search] Total request completed in {total_time:.2f} seconds")

        response = make_response(json.dumps({"matches": matches}, sort_keys=False), 200)
        response.headers["Content-Type"] = "application/json"
        return response

    except Exception as e:
        logger.exception("[search] Exception occurred:")
        return jsonify({"error": str(e)}), 500
    
if __name__ == '__main__':
    app.run(host='0.0.0.0', port=port)
Chat

New Conversation

ðŸ¤“ Explain a complex thing

Explain Artificial Intelligence so that I can explain it to my six-year-old child.


ðŸ§  Get suggestions and create new ideas

Please give me the best 10 travel ideas around the world


ðŸ’­ Translate, summarize, fix grammar and moreâ€¦

Translate "I love you" French


GPT-4o Mini
Hello, how can I help you today?
GPT-4o Mini
coin image
10
Upgrade




import numpy as np
import torch
import os
import cv2
from scipy.spatial.distance import cdist
from torch.utils.data import Dataset

class SparseDataset(Dataset):
    def __init__(self, root_dir, max_keypoints):
        self.nfeatures = max_keypoints
        self.sift = cv2.SIFT_create()
        self.matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)

        self.files = [
            os.path.join(subdir, fname)
            for subdir, _, filenames in os.walk(root_dir)
            for fname in filenames
            if fname.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp'))
        ]

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        file_name = self.files[idx]

        # Load image (grayscale)
        image = cv2.imread(file_name, cv2.IMREAD_GRAYSCALE)
        if image is None:
            raise RuntimeError(f"Failed to load image {file_name}")

        # TODO: Replace this with your actual homography per sample if available
        M = np.eye(3, dtype=np.float32)  # identity for example

        # Warp image with homography M
        h, w = image.shape
        warped = cv2.warpPerspective(image, M, (w, h))

        # Detect SIFT keypoints and descriptors
        kp1, descs1 = self.sift.detectAndCompute(image, None)
        kp2, descs2 = self.sift.detectAndCompute(warped, None)

        # Limit number of keypoints to nfeatures
        kp1 = kp1[:self.nfeatures]
        kp2 = kp2[:self.nfeatures]
        descs1 = descs1[:len(kp1)]
        descs2 = descs2[:len(kp2)]

        # Convert keypoints to numpy arrays [N, 2]
        kp1_np = np.array([[kp.pt[0], kp.pt[1]] for kp in kp1], dtype=np.float32)
        kp2_np = np.array([[kp.pt[0], kp.pt[1]] for kp in kp2], dtype=np.float32)

        # Get keypoint responses as scores
        scores1_np = np.array([kp.response for kp in kp1], dtype=np.float32)
        scores2_np = np.array([kp.response for kp in kp2], dtype=np.float32)

        # Project keypoints1 using homography M
        kp1_projected = cv2.perspectiveTransform(kp1_np[None], M)[0]

        # Compute distances between projected kp1 and kp2
        dists = cdist(kp1_projected, kp2_np)

        # Find mutual nearest neighbors within 3 pixel threshold
        min1 = np.argmin(dists, axis=0)
        min2 = np.argmin(dists, axis=1)
        min1v = np.min(dists, axis=1)
        min1f = min2[min1v < 3]
        xx = np.where(min2[min1] == np.arange(len(min1)))[0]
        matches = np.intersect1d(min1f, xx)

        # Identify missing matches (keypoints with no match)
        missing1 = np.setdiff1d(np.arange(kp1_np.shape[0]), min1[matches])
        missing2 = np.setdiff1d(np.arange(kp2_np.shape[0]), matches)

        # Build matches matrix
        MN = np.stack([min1[matches], matches])
        MN2 = np.stack([missing1, np.full_like(missing1, len(kp2))])
        MN3 = np.stack([np.full_like(missing2, len(kp1)), missing2])
        all_matches = np.concatenate([MN, MN2, MN3], axis=1)

        # Convert images to tensors with shape [1, H, W] and scale [0,1]
        image_t = torch.from_numpy(image / 255.).unsqueeze(0).float()
        warped_t = torch.from_numpy(warped / 255.).unsqueeze(0).float()

        return {
            'keypoints0': torch.from_numpy(kp1_np[None]).float(),                # [1, N0, 2]
            'keypoints1': torch.from_numpy(kp2_np[None]).float(),                # [1, N1, 2]
            'descriptors0': torch.from_numpy((descs1.T / 256.).astype(np.float32)),  # [128, N0]
            'descriptors1': torch.from_numpy((descs2.T / 256.).astype(np.float32)),  # [128, N1]
            'scores0': torch.from_numpy(scores1_np),                             # [N0]
            'scores1': torch.from_numpy(scores2_np),                             # [N1]
            'image0': image_t,                                                    # [1, H, W]
            'image1': warped_t,                                                   # [1, H, W]
            'all_matches': torch.from_numpy(all_matches),                        # [2, N_matches]
            'file_name': os.path.basename(file_name),
            'skip_train': False
        }

